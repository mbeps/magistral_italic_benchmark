{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magistral_benchmark import MagistralBenchmarkConfig, MagistralBenchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e893be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MagistralBenchmarkConfig(\n",
    "    model_name=\"mistralai/Magistral-Small-2506\",\n",
    "    tokenizer_name=\"mistralai/Mistral-Nemo-Instruct-2407\",\n",
    "    batch_size=8,\n",
    "    min_vram_gb=8,\n",
    "    test_file=\"./data/test.jsonl\",\n",
    "    max_new_tokens=350,\n",
    "    max_eval_samples=None,\n",
    "    system_message=\"Sei un assistente utile e intelligente.\",\n",
    "    output_prefix=\"magistral_small\",\n",
    "    # Quantization settings\n",
    "    use_quantization=True,\n",
    "    quantization_type=\"nf4\",\n",
    "    quantization_compute_dtype=\"float16\",\n",
    "    # Optimizations\n",
    "    use_flash_attention=True,\n",
    "    use_torch_compile=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0aef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CUDA optimizations enabled (TF32, cuDNN benchmark)\n",
      "‚úÖ CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3090\n",
      "VRAM: 23.6 GB\n",
      "‚úÖ GPU has sufficient VRAM for the model\n"
     ]
    }
   ],
   "source": [
    "benchmark = MagistralBenchmark(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b52b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MAGISTRAL BENCHMARK\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "MAGISTRAL BENCHMARK CONFIGURATION\n",
      "============================================================\n",
      "‚úì Model: mistralai/Magistral-Small-2506\n",
      "‚úì Tokenizer: mistralai/Mistral-Nemo-Instruct-2407\n",
      "‚úì Test file: ./data/test.jsonl\n",
      "‚úì Max samples: All\n",
      "‚úì Batch size: 8\n",
      "‚úì Max new tokens: 350\n",
      "‚úì Min VRAM required: 8GB\n",
      "‚úì Quantization: nf4 (float16)\n",
      "‚úì Flash Attention 2: Enabled\n",
      "‚úì torch.compile: Enabled\n",
      "‚úì Output prefix: magistral_small\n",
      "‚úì System message: Sei un assistente utile e intelligente.\n",
      "============================================================\n",
      "\n",
      "üìö Loading ITALIC dataset...\n",
      "Loaded 10000 questions\n",
      "\n",
      "Using 10000 questions for evaluation\n",
      "Categories: {'art_history': 980, 'civic_education': 973, 'current_events': 92, 'geography': 979, 'history': 978, 'lexicon': 979, 'literature': 984, 'morphology': 140, 'orthography': 971, 'synonyms_and_antonyms': 971, 'syntax': 973, 'tourism': 980}\n",
      "üîÑ Loading mistralai/Magistral-Small-2506...\n",
      "Loading tokenizer: mistralai/Mistral-Nemo-Instruct-2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Flash Attention 2 not available - using standard attention\n",
      "Loading model with optimizations...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a23e375a3d425ea35b51e5b811a7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model with torch.compile for optimization...\n",
      "‚úÖ Model compiled successfully!\n",
      "‚úÖ Model loaded successfully!\n",
      "Model device: cuda:0\n",
      "Model dtype: torch.float16\n",
      "GPU Memory - Allocated: 13.19 GB, Available: 8.19 GB\n",
      "üöÄ Optimal batch size determined: 8\n",
      "\n",
      "üß™ Testing inference...\n",
      "Question: La frase \"Secondo recenti sondaggi il candidato repubblicano gode di scarsissima popolarit√†: la poss...\n",
      "Test response: 'C'\n",
      "Expected answer: 'D'\n",
      "Extracted answer: 'C'\n",
      "Correct: False\n",
      "\n",
      "==================================================\n",
      "STARTING EVALUATION\n",
      "==================================================\n",
      "\n",
      "üîç Evaluating mistralai/Magistral-Small-2506 on 10000 questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [31:44<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä FINAL RESULTS:\n",
      "Total questions: 10000\n",
      "Correct answers: 7597\n",
      "Accuracy: 0.7597 (75.97%)\n",
      "\n",
      "üìà RESULTS BY CATEGORY:\n",
      "------------------------------------------------------------\n",
      "Category                      Accuracy  Correct    Total\n",
      "------------------------------------------------------------\n",
      "art_history                     71.53%      701      980\n",
      "civic_education                 75.64%      736      973\n",
      "current_events                  80.43%       74       92\n",
      "geography                       82.02%      803      979\n",
      "history                         82.00%      802      978\n",
      "lexicon                         86.21%      844      979\n",
      "literature                      74.80%      736      984\n",
      "morphology                      47.14%       66      140\n",
      "orthography                     62.31%      605      971\n",
      "synonyms_and_antonyms           89.60%      870      971\n",
      "syntax                          65.06%      633      973\n",
      "tourism                         74.18%      727      980\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîç SAMPLE PREDICTIONS:\n",
      "\n",
      "Example 1 ‚úÖ CORRECT:\n",
      "  Category: syntax\n",
      "  Question: Nella frase \"Lungo la riva ha raccolto alcune erbe spontanee\", \"Lungo la riva\" √® un sintagma:...\n",
      "  Expected: C\n",
      "  Predicted: C\n",
      "  Raw output: 'C...'\n",
      "\n",
      "Example 2 ‚úÖ CORRECT:\n",
      "  Category: literature\n",
      "  Question: Come si chiamava il periodico, pubblicato dal 1764 al 1766, principale strumento di diffusione del p...\n",
      "  Expected: C\n",
      "  Predicted: C\n",
      "  Raw output: 'C...'\n",
      "\n",
      "Example 3 ‚ùå INCORRECT:\n",
      "  Category: orthography\n",
      "  Question: La frase \"Secondo recenti sondaggi il candidato repubblicano gode di scarsissima popolarit√†: la poss...\n",
      "  Expected: D\n",
      "  Predicted: C\n",
      "  Raw output: 'C...'\n",
      "\n",
      "Example 4 ‚ùå INCORRECT:\n",
      "  Category: literature\n",
      "  Question: Quale tra le seguenti riviste non appartiene al primo novecento?...\n",
      "  Expected: A\n",
      "  Predicted: D\n",
      "  Raw output: 'D...'\n",
      "\n",
      "üíæ Saving results...\n",
      "Detailed results saved to 'magistral_small_results.csv'\n",
      "Summary saved to 'magistral_small_summary.json'\n",
      "\n",
      "üéâ EVALUATION COMPLETED!\n",
      "============================================================\n",
      "üìä Model: mistralai/Magistral-Small-2506\n",
      "üìä Final accuracy: 0.7597 (75.97%)\n",
      "üìä Total questions evaluated: 10000\n",
      "üìä Batch size used: 8\n",
      "============================================================\n",
      "\n",
      "üßπ Final cleanup...\n",
      "Final GPU memory usage: 0.01GB\n",
      "‚úÖ mistralai/Magistral-Small-2506 benchmark complete! üöÄ\n"
     ]
    }
   ],
   "source": [
    "results, accuracy, category_stats = benchmark.run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af5a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark completed with 0.7597 accuracy\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nBenchmark completed with {accuracy:.4f} accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae45ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved with prefix: magistral_small\n"
     ]
    }
   ],
   "source": [
    "print(f\"Results saved with prefix: {config.output_prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffae70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà RESULTS BY CATEGORY:\n",
      "------------------------------------------------------------\n",
      "Category                      Accuracy  Correct    Total\n",
      "------------------------------------------------------------\n",
      "art_history                     71.53%      701      980\n",
      "civic_education                 75.64%      736      973\n",
      "current_events                  80.43%       74       92\n",
      "geography                       82.02%      803      979\n",
      "history                         82.00%      802      978\n",
      "lexicon                         86.21%      844      979\n",
      "literature                      74.80%      736      984\n",
      "morphology                      47.14%       66      140\n",
      "orthography                     62.31%      605      971\n",
      "synonyms_and_antonyms           89.60%      870      971\n",
      "syntax                          65.06%      633      973\n",
      "tourism                         74.18%      727      980\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Optional: Access individual components if you need custom analysis\n",
    "benchmark.analyse_results_by_category(category_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c692dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç SAMPLE PREDICTIONS:\n",
      "\n",
      "Example 1 ‚úÖ CORRECT:\n",
      "  Category: syntax\n",
      "  Question: Nella frase \"Lungo la riva ha raccolto alcune erbe spontanee\", \"Lungo la riva\" √® un sintagma:...\n",
      "  Expected: C\n",
      "  Predicted: C\n",
      "  Raw output: 'C...'\n",
      "\n",
      "Example 2 ‚úÖ CORRECT:\n",
      "  Category: literature\n",
      "  Question: Come si chiamava il periodico, pubblicato dal 1764 al 1766, principale strumento di diffusione del p...\n",
      "  Expected: C\n",
      "  Predicted: C\n",
      "  Raw output: 'C...'\n",
      "\n",
      "Example 3 ‚úÖ CORRECT:\n",
      "  Category: syntax\n",
      "  Question: Nella frase \"le ho scritto una lettera con il cuore\" che funzione logica svolge l'espressione \"con i...\n",
      "  Expected: C\n",
      "  Predicted: C\n",
      "  Raw output: 'C...'\n",
      "\n",
      "Example 4 ‚úÖ CORRECT:\n",
      "  Category: civic_education\n",
      "  Question: Le fonti di produzione si dividono in:...\n",
      "  Expected: C\n",
      "  Predicted: C\n",
      "  Raw output: 'C...'\n",
      "\n",
      "Example 5 ‚úÖ CORRECT:\n",
      "  Category: art_history\n",
      "  Question: L'arte, cos√¨ come rappresentata nel libro sulla \"Storia dell'Arte\", datato 1842, veniva suddivisa in...\n",
      "  Expected: C\n",
      "  Predicted: C\n",
      "  Raw output: 'C...'\n",
      "\n",
      "Example 6 ‚ùå INCORRECT:\n",
      "  Category: orthography\n",
      "  Question: La frase \"Secondo recenti sondaggi il candidato repubblicano gode di scarsissima popolarit√†: la poss...\n",
      "  Expected: D\n",
      "  Predicted: C\n",
      "  Raw output: 'C...'\n",
      "\n",
      "Example 7 ‚ùå INCORRECT:\n",
      "  Category: literature\n",
      "  Question: Quale tra le seguenti riviste non appartiene al primo novecento?...\n",
      "  Expected: A\n",
      "  Predicted: D\n",
      "  Raw output: 'D...'\n",
      "\n",
      "Example 8 ‚ùå INCORRECT:\n",
      "  Category: geography\n",
      "  Question: Pontecorvo, in provincia di Frosinone, detiene l'unica produzione Dop di quale eccellenza?...\n",
      "  Expected: A\n",
      "  Predicted: C\n",
      "  Raw output: 'C...'\n",
      "\n",
      "Example 9 ‚ùå INCORRECT:\n",
      "  Category: tourism\n",
      "  Question: Quanti isolotti compongono \"Le isole Li Galli\"?...\n",
      "  Expected: A\n",
      "  Predicted: C\n",
      "  Raw output: 'C...'\n",
      "\n",
      "Example 10 ‚ùå INCORRECT:\n",
      "  Category: syntax\n",
      "  Question: Che tipo di complemento √® contenuto nella frase: Ci siamo fermati in una trattoria perch√© avevamo fa...\n",
      "  Expected: B\n",
      "  Predicted: A\n",
      "  Raw output: 'A...'\n"
     ]
    }
   ],
   "source": [
    "benchmark.show_sample_predictions(results, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
